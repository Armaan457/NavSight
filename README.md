# NavSight
People who are unable to see, face unique challenges in communicating and navigating their surroundings. To help in this issue, we are making a tool for the visually impaired people. It will help them to know about their surroundings and the objects near them. For a comfortable user experience the app is voice controlled for the user side while the helper side has full access to the the assigned person's location and emergency status and can call for help when neccessary .

# Technologies used
**Frontend**: HTML, CSS, Javascript <br>
**Backend**: Django <br>
**Database**: SQLite <br>
**Deep Learning models**: YOLO and BLIP <br>

# Setup

Clone the repository:

```sh
> git clone https://github.com/Armaan457/NavSight.git
> cd NavSight
```
Create and activate a virtual environment:

```sh
> python -m venv venv
> venv\Scripts\activate
  ```
Install dependencies:

```sh
> pip install -r requirements.txt
```

Run the development server:

```sh
> python manage.py runserver
```

# Developers
1. Armaan Jagirdar
2. Nimish Goyal
3. Yajat Pahuja

Developed during the intra society Projectathon conducted by the Thapar ACM student chapter in 2024
